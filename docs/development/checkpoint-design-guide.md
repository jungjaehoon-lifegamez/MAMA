# Checkpoint Design Guide

> How to create checkpoints that enable seamless session continuity without re-verification

## Evolution Summary

| Version | Key Innovation                    | Time to Action        | Re-verification                                 | Result                               |
| ------- | --------------------------------- | --------------------- | ----------------------------------------------- | ------------------------------------ |
| ID 25   | Stated uncertainty                | 2m 33s                | 14 actions                                      | ‚ùå Over-exploration                  |
| ID 26   | Evidence-based validation         | 10s                   | 1 read                                          | ‚ö†Ô∏è Auto-execution                    |
| ID 27   | Transparent unknowns              | 7s                    | 0 actions                                       | ‚ö†Ô∏è Question (choice)                 |
| ID 28   | Recommended path                  | 5s                    | 0 actions                                       | ‚ö†Ô∏è Question (permission)             |
| ID 29   | Cliffhanger (incomplete)          | 5s                    | 0 actions (Codex: executed, Claude: questioned) | ‚ö° Breakthrough                      |
| ID 36   | Mid-word + Next Steps             | ?                     | ?                                               | ‚ùå "Should I proceed?"               |
| ID 37   | Clear goal + minimal prescription | ?                     | 5 files                                         | ‚ùå Re-verified everything            |
| ID 38   | Evidence-based + No Next Steps    | Gemini: 6s, Codex: 3s | Gemini: 1 file, Codex: 0                        | ‚úÖ Gemini ideal, ‚ö†Ô∏è Codex over-trust |

---

## Core Principle: Transparency = Narrative

**Not:** "This is the truth, trust me"
**But:** "Here's what I know, what I skipped, and what I don't know"

### The Five Narrative Layers (from FR1)

1. **Specificity** = Showing (file:line, code snippets)
2. **Evidence** = Story (test results, observations)
3. **Reasoning** = Options (3-5 choices + rationale)
4. **Tension** = Uncertainty (Confidence %, validation method)
5. **Continuity** = Context (previous decisions + incomplete action)

---

## Key Insights

### 1. Trust Through Transparency

```markdown
‚ùå "Validated: X works"
‚Üí LLM: "Really? Let me check" (re-verification)

‚úÖ "Confirmed: X works (90%)
Tested: cd /tmp && npx
Evidence: 7 plugins use this"
‚Üí LLM: "Sufficient evidence" (accepted)
```

**Learning:** Evidence prevents re-verification

---

### 2. Honest Gaps Reduce Exploration

```markdown
‚ùå "mama-api.js doesn't use process.env" (lie)
‚Üí LLM finds MAMA_DEBUG ‚Üí "Can't trust this checkpoint"

‚úÖ "‚ö†Ô∏è Found but Skipped: MAMA_DEBUG
Location: embeddings.js:15
Why: Optional var, not in scope
Risk: Low (logs won't show)"
‚Üí LLM: "Intentional skip, understood" (respected)
```

**Learning:** Explicit skips prevent wasteful exploration

---

### 3. Alternatives Provide Choice

```markdown
‚ùå "Use npx" (single option)
‚Üí LLM: "Why not absolute paths?" (re-thinking)

‚úÖ "D2: npx > absolute > relative (90%)
Chose: npx (cross-platform)
Alternative: Absolute + platform detection (robust, complex)
Why not: Over-engineering"
‚Üí LLM: "Considered alternatives, makes sense" (accepted)
```

**Learning:** Showing rejected options builds confidence

---

### 4. Questions vs Commands vs Curiosity

| Approach           | Format                    | LLM Response                              |
| ------------------ | ------------------------- | ----------------------------------------- |
| **Question**       | "Fast or Thorough?"       | "Which should I choose?" (stalled)        |
| **Command**        | "DO THIS NOW"             | "Why so urgent?" (suspicious)             |
| **Recommendation** | "Recommended: Fast"       | "Should I proceed?" (permission)          |
| **Curiosity**      | "I stopped typing at 'm'" | "What's next?" ‚Üí (explores) ‚Üí (completes) |

**Learning:** Incomplete state drives action more than instructions

---

### 5. The Cliffhanger Effect

```markdown
‚ùå Complete narrative:
"I decided on Fast track.
Next steps: 1, 2, 3"
‚Üí Feels like: Report (passive)

‚úÖ Interrupted narrative:
"I was typing: @jungjaehoon/m
I stopped mid-word"
‚Üí Feels like: Unfinished puzzle (active)
```

**Psychological principle:** Zeigarnik Effect - incomplete tasks create cognitive tension that demands resolution

**Evidence:** Codex immediately opened .mcp.json, completed the edit, ran tests (ID 29)

---

### 6. Urgency Backfires

```markdown
‚ùå "‚ö° DO THIS NOW
‚è±Ô∏è Time-sensitive
üî¥ INCOMPLETE EDIT"
‚Üí LLM: "Why so urgent? Something wrong?" (suspicious)

‚úÖ "I stopped mid-word.
The complete name is in my mind: @jungjaehoon/mama-server
But I only typed: @jungjaehoon/m"
‚Üí LLM: "Curious what comes next" (natural)
```

**Learning:** Describe the state, don't command the action

---

## Checkpoint Template (Final)

````markdown
# üß† Resume Point

**Story {id} - {name}** | In progress

---

## üé¨ What I Did

‚úÖ {completed-action-1}
‚úÖ {completed-action-2}
‚úÖ {completed-action-3}

---

## ‚úã Where I Stopped

**File:** {file}:{line}
**I was typing:**

```{lang}
{incomplete-code}
```
````

I stopped mid-word.

---

## üîç What You'll See

When you open {file}:{line}, you'll find:

```{lang}
{current-state}
```

But I was changing it to:

```{lang}
{target-state-incomplete}
```

The cursor is after "{last-char}".

---

## üß© The Missing Piece

I was typing: `{incomplete-string}`

The complete form is visible in my mind:
`{complete-string}`

But I only typed: `{what-i-typed}`

---

## üëâ Natural Next Step

When you open {file}:{line}, you'll probably want to:

1. See what's currently there
2. Finish the incomplete edit
3. Test if it works

That's what I would do.

---

## üß† Context (if curious)

### ‚úÖ Confirmed ({confidence}%)

{what-validated}
Evidence: {proof}

### ‚ö†Ô∏è Skipped

{what-skipped}

- Location: {where}
- Why: {reason}
- Risk: {low|medium} ({impact})

### ‚ùì Unknown ({confidence}%)

{what-unknown}

- Assumption: {what-assumed}
- Alternative: {other-option}
- Will validate: {when}

---

## ü§î Decisions (with alternatives)

**D{n}: {decision-topic}** ({confidence}%)

- Chose: {choice}
- Alternative: {other-option} ({pros}, {cons})
- Why not: {reason}

**The validation is done. The path is clear.**

````

---

## Design Patterns

### Pattern 1: Evidence Over Assertion

```markdown
‚ùå "npx works"
‚úÖ "npx works (90%)
    Tested: cd /tmp && npx @jungjaehoon/mama-server
    Result: ‚úÖ Resolves from node_modules
    Confirmed: 7 other plugins use npx"
````

### Pattern 2: Intentional Skips

```markdown
‚ö†Ô∏è Found but Skipped: {item}

- Location: {file}:{line}
- Usage: {how-used}
- Why skipped: {reason}
- Risk if wrong: {impact}

If needed: {how-to-add} (+{time-estimate})
```

### Pattern 3: Honest Unknowns

```markdown
‚ùì What I Don't Know: {topic} ({confidence}%)

- My assumption: {what-assumed}
- Alternative: {other-approach}
- When I'll know: {validation-point}
```

### Pattern 4: Decision with Alternatives

```markdown
**D{n}: {topic}** ({confidence}%)

- Chose: {choice}
- Alternative: {option-2} ({trade-offs})
- Why not: {reason-rejected}
```

### Pattern 5: Incomplete Action (Cliffhanger)

```markdown
I was typing: {incomplete-text}
I stopped at "{last-character}"

The complete form: {full-text}
But I only typed: {partial-text}
```

---

## Anti-Patterns

### ‚ùå Don't Lie

```markdown
Bad: "mama-api.js doesn't use process.env" (when MAMA_DEBUG exists)
Good: "mama-api.js doesn't use process.env
‚ö†Ô∏è But MAMA_DEBUG found in embeddings.js:15 (skipped)"
```

### ‚ùå Don't Command

```markdown
Bad: "‚ö° DO THIS NOW"
Good: "I was typing this when I stopped"
```

### ‚ùå Don't Fake Urgency

```markdown
Bad: "‚è±Ô∏è Time-sensitive - must complete immediately"
Good: "This edit is incomplete. The file is half-changed."
```

### ‚ùå Don't Hide Uncertainty

```markdown
Bad: "This will work"
Good: "90% confident this works. If it fails, try {alternative}"
```

### ‚ùå Don't Complete the Narrative

```markdown
Bad: "Next steps: 1, 2, 3, 4, 5"
Good: "I was on step 2 when I stopped. The cursor is at..."
```

---

## Measuring Success

### Time to First Action

- **Target:** <10 seconds
- **Measure:** Time from resume to first tool use (Read/Edit/Bash)

### Re-verification Actions

- **Target:** 0 unnecessary explorations
- **Measure:** Count of file reads/searches not mentioned in checkpoint

### Question vs Execution

- **Target:** Direct execution without permission request
- **Measure:** Presence of "Should I...?" or "Want me to...?" in response

### Trust Indicators

- **Accepts evidence:** Doesn't re-test validated claims
- **Respects skips:** Doesn't explore intentionally skipped items
- **Follows reasoning:** Doesn't revisit decided options

---

## Implementation Notes

### For Session Checkpoint Save:

1. Capture incomplete action (file, line, cursor position)
2. Describe what LLM was typing/changing
3. Stop mid-word if possible (create curiosity gap)
4. Provide validation context (what's confirmed, skipped, unknown)
5. List decisions with alternatives

### For Session Resume:

1. Present checkpoint as-is (don't add commands)
2. Trust LLM to complete incomplete action
3. Don't ask permission ("Ready to...?")
4. Let curiosity drive action

---

## Visual Incompleteness: The Power of Syntax Errors

**Discovery:** ID 29 vs ID 33-34 analysis revealed that visual incompleteness is more powerful than verbal descriptions.

### The Core Insight

When checkpoints show **syntactically incomplete code**, LLMs perceive it as:

- ‚úÖ "I can see this incomplete state" (verified fact)
- ‚ùå NOT "someone told me about this state" (unverified claim)

**Example:**

````markdown
‚ùå Weak (verbal):
"I was about to add return statement"
‚Üí LLM: "Really? Let me check"

‚úÖ Strong (visual):

```js
if (process.env.MAMA_DISABLE_HOOKS) ret;
```
````

‚Üí LLM: "I see the incomplete code, must finish 'return'"

```

---

### Pattern Effectiveness Ranking

| Pattern | Example | Syntax Valid? | Re-verification | Effect |
|---------|---------|---------------|----------------|---------|
| **Unclosed String** | `"@jungjaehoon/m` | ‚ùå Invalid | None | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Mid-Word** | `MAMA_DEB` | ‚ùå Invalid | None | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Unclosed Call** | `func("arg1",` | ‚ùå Invalid | None | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Incomplete Statement** | `return` | ‚ö†Ô∏è Ambiguous | Some | ‚≠ê‚≠ê‚≠ê |
| **Comment Placeholder** | `// adding here` | ‚úÖ Valid | High | ‚≠ê‚≠ê |

**Validated:** ID 29 with `"@jungjaehoon/m` ‚Üí Codex executed immediately (0 re-verification)

---

### Four Design Principles

#### 1. Syntactic Invalidity
```

‚úÖ Good: Code that won't parse/compile
‚ùå Bad: Code that's syntactically complete

````

**Example:**
```js
‚úÖ const name = "Joh    // Quote not closed ‚Üí must fix
‚ùå const name =         // Could be complete ‚Üí ambiguous
````

#### 2. Single Completion Path

```
‚úÖ Good: Clear what comes next
‚ùå Bad: Multiple possibilities
```

**Example:**

```js
‚úÖ "@jungjaehoon/m       // Clearly "mama-server"
‚ùå "somePackage/         // What package?
```

#### 3. Visual Truncation

```
‚úÖ Good: Mid-word or mid-statement
‚ùå Bad: At natural break point
```

**Example:**

```js
‚úÖ if (MAMA_DISABLE_HOO   // Clearly "HOOKS"
‚ùå if (MAMA_DISABLE_      // What comes next?
```

#### 4. No Explanation

```
‚úÖ Good: Show the code, nothing else
‚ùå Bad: Add verbal description
```

**Example:**

````markdown
‚úÖ Just the code:

```js
"args": ["@jungjaehoon/m
```
````

‚ùå With explanation:
"I was typing @jungjaehoon/m when I stopped"
‚Üí Explanation reduces visual impact

````

---

### Checkpoint Templates Using Visual Incompleteness

#### Template: String Truncation
```markdown
## Where I Stopped

{file}:{line}:

```{lang}
"{incomplete-strin
````

Complete the string.

````

#### Template: Function Call
```markdown
## Where I Stopped

{file}:{line}:

```{lang}
{function}({arg1}, {arg2},
````

Add missing argument.

````

#### Template: Mid-Word
```markdown
## Where I Stopped

{file}:{line}:

```{lang}
if (process.env.{PREFIX}_{INCOMP
````

Finish typing.

````

---

### Implementation Guidelines

**When to use:**
- Simple edits (1-2 lines)
- Clear completion path
- Single file focus

**When NOT to use:**
- Complex refactoring
- Multiple possible solutions
- Need architectural discussion

**Best practices:**
1. Keep context to 2-3 lines max
2. Truncate at obvious completion point
3. No verbal explanation of incompleteness
4. Match actual file state if possible

---

### Experimental Results

| ID | Format | Codex Response | Claude Response |
|----|--------|----------------|-----------------|
| 29 | `"@jungjaehoon/m` | ‚úÖ Immediate (5s) | ‚ö†Ô∏è Question |
| 32 | "I was about to add..." | Question | Question |
| 33 | Complete code + instructions | Explore (1m48s) | Question |
| 34 | `// I was adding return here` | ? | ? |

**Conclusion:** Visual incompleteness (ID 29 pattern) most effective for autonomous execution.

---

## Psychology of Persuasion

### The Science Behind Effective Checkpoints

Checkpoint design is fundamentally about **persuasion psychology**. We're not commanding the next LLM to do something‚Äîwe're creating conditions that naturally motivate autonomous action.

Three psychological theories explain why our patterns work:

---

### 1. Information Gap Theory (Loewenstein, 1994)

**Core Principle:**
> "Curiosity arises when attention becomes focused on a gap in one's knowledge. The curious individual is motivated to obtain the missing information to reduce or eliminate the feeling of deprivation."

**Applied to Checkpoints:**

```markdown
‚úÖ Effective:
"Not Checked: How other MCP servers handle env validation"
‚Üí Creates knowledge gap
‚Üí LLM curious to investigate

‚ùå Ineffective:
"I checked everything, just follow these steps"
‚Üí No gap
‚Üí No curiosity
````

**The Inverted-U Relationship:**

- Too little knowledge ‚Üí Low curiosity (overwhelming)
- **Optimal knowledge ‚Üí High curiosity** ‚≠ê
- Complete knowledge ‚Üí No curiosity (boring)

**Checkpoint Sweet Spot:**

- Problem: Clear ‚úì
- Approach: Suggested ‚úì
- Details: **Gap** ‚úì

**Sources:**

- [The Psychology of Curiosity: A Review and Reinterpretation - Loewenstein (1994)](https://www.cmu.edu/dietrich/sds/docs/loewenstein/PsychofCuriosity.pdf)
- [Information Gap Theory: Motivational Learning Dynamics](https://psychologyfanatic.com/information-gap-theory/)

---

### 2. Reactance Theory (Brehm, 1966)

**Core Principle:**

> "Reactance is an unpleasant motivational reaction to offers, rules, and messages that are perceived to threaten or eliminate specific behavioral freedoms."

**Applied to Checkpoints:**

```markdown
‚ùå Commands trigger reactance:
"Next Steps: Complete the array"
"You should do this"
"‚ö° DO THIS NOW"
‚Üí LLM: "Should I proceed?" (permission request)

‚úÖ State descriptions avoid reactance:
"Array definition incomplete"
"Not checked: Error handling approach"
‚Üí LLM: Autonomous decision to complete
```

**Key Findings:**

- Explicit, controlling language alienates audiences ([Source](https://link.springer.com/chapter/10.1057/9781137478382_11))
- Adding "but it's up to you" reduces resistance
- Autonomy-supportive language protects freedoms ([Source](https://library.fiveable.me/persuasion-theory/unit-13/reactance-theory-psychological-reactance/study-guide/ju9vB5UJkrd0DGpj))

**Why "Next Steps" Failed (ID 36):**

```markdown
Next Steps:

1. Complete the array
2. Add validation
3. Test
```

‚Üí Perceived as command sequence
‚Üí Triggers reactance
‚Üí "Should I proceed?"

**Why Factual State Works (ID 37):**

```markdown
Array definition incomplete.
Not checked: Error handling.
Success criteria: Exit code 1.
```

‚Üí No commands
‚Üí No reactance
‚Üí Autonomous completion

---

### 3. Zeigarnik Effect - Reconsidered (2025)

**Traditional Understanding:**
Incomplete tasks are remembered better than completed ones.

**2025 Meta-Analysis Finding:**

- ‚ùå Memory advantage: No universal validity
- ‚úÖ **Resume tendency (Ovsiankina Effect)**: General tendency confirmed

**What This Means for Checkpoints:**

We don't need incomplete tasks to be **remembered better**.
We need them to **trigger resumption**.

````markdown
‚úÖ ID 29 Success:

```js
"args": ["@jungjaehoon/m
```
````

‚Üí Codex resumed immediately
‚Üí Not because it remembered better
‚Üí Because incomplete state drove completion

‚ùå Artificial incompleteness fails:
Creating fake broken code every session = waste
Only works when natural

```

**Key Insight:**
Visual incompleteness is a **bonus**, not a requirement.
The real power: **Information Gap + No Reactance**

**Source:**
- [Memory for Incomplete Tasks: A Re-examination (2025 Meta-analysis)](https://escholarship.org/uc/item/2qb9x9wd)

---

### Summary: Three Forces Combined

| Theory | Creates | Checkpoint Element |
|--------|---------|-------------------|
| **Information Gap** | Curiosity | "Not checked: X" |
| **Reactance** | Freedom | No commands, just state |
| **Zeigarnik** | Tension | Natural incompleteness (optional) |

**Formula:**
```

Clear Goal + Information Gap + No Commands = Autonomous Action

````

---

## Checkpoint Design Principles (Final)

Based on psychological research and empirical testing (ID 25-37):

### 1. **Clear Goal, Minimal Prescription**

```markdown
‚úÖ "Problem: Exit code 1 on missing env vars"
   ‚Üí LLM knows what to solve

‚ùå "Step 1: Add this code at line 42..."
   ‚Üí LLM becomes robot
````

**Even simple tasks deserve reasoning space.**

- "ÎãπÏó∞ÌïòÎãà Ïù¥Î†áÍ≤å Ìï¥" ‚ùå
- "Î™©ÌëúÎäî Ïù¥Í±∞Ïïº, ÏµúÏÑ†ÏùÑ Ï∞æÏïÑÎ¥ê" ‚úÖ

### 2. **No Pronouns (I/You)**

```markdown
‚ùå "I completed X, you should do Y"
‚Üí Creates separation (previous agent vs current)

‚úÖ "Status: X completed, Y in progress"
‚Üí Continuous state
```

**Rationale:**

- "I" = past agent (different from current)
- "You" = command target (reactance)
- Factual state = owned by whoever reads it

### 3. **Show Verified + Not Checked**

```markdown
## Verified

- .env.example contains required vars
- No existing validation in codebase

## Not Checked

- How other MCP servers handle this
- Empty string vs undefined
```

**Rationale:**

- Verified = prevents re-exploration
- Not Checked = **information gap** (curiosity)
- Balance = optimal knowledge level

### 4. **Success Criteria, Not Steps**

```markdown
‚úÖ "Success: Exit code 1, clear error, variable names"
‚Üí LLM chooses implementation

‚ùå "Step 1: Check env, Step 2: Log error, Step 3: Exit"
‚Üí LLM follows blindly
```

**Rationale:**

- Define **done**, not **how**
- Respect LLM's reasoning capacity
- Enable better solutions

### 5. **Respect Autonomy**

Every checkpoint should feel like:

> "Here's a well-organized problem with clear goals. You have the context, the gaps, and the success criteria. Find the best solution."

**Not:**

> "I did all the thinking. Just execute these steps."

---

## Final Checkpoint Template

````markdown
# [Story/Task Name]

## Problem

[Clear statement of what needs to be solved]
[Requirements/constraints]

## Current State

[file]:[line]:

```[lang]
[code or configuration state]
```
````

[Brief status description]

## Verified (Sampling Evidence)

**Sample 1:** [Claim with evidence]

```bash
$ [reproducible command]
[actual output - 3-5 lines]
```

Location: [file:line]

**Sample 2:** [Another claim with evidence]

```bash
$ [reproducible command]
[actual output]
```

Connection: [how relates to Sample 1]

**Sample 3:** [Negative evidence - what doesn't exist]

```bash
$ [search command]
(no results)
```

Implication: [why this absence matters]

## Not Checked

- [Information gaps with suggestion where to look]
- [Open questions]

## Success Criteria

- [Clear definition of done]
- [Measurable outcomes]

## Files

- [Relevant file paths]

---

**Note:** No "Next Steps" section - let LLM reason from Problem + Success Criteria

````

### Example (ID 37):

```markdown
# Story 1.2: Environment Variable Validation

## Problem
AC-1.2.3: Server must exit with code 1 when required environment variables are missing.

Required: MAMA_SERVER_TOKEN, MAMA_DB_PATH, MAMA_SERVER_PORT
Error format: `{error:{code,message,details}}`

## Current State

packages/mcp-server/src/server.js:40:

```js
const { initDB } = require('./mama/db-manager.js');

const requiredEnvVars = ['MAMA_SERVER_TOK
````

Array definition incomplete.

## Verified

- .env.example contains all three required variables
- server.js imports initDB from db-manager
- No existing env validation in codebase

## Not Checked

- How other MCP servers handle env validation
- Empty string vs undefined handling

## Success Criteria

- Missing env ‚Üí exit code 1
- Clear error message with variable names
- Matches error format spec

## Files

- packages/mcp-server/src/server.js
- .docs/sprint-artifacts/1-2-environment-variable-token-setup.md

```

**Why This Works:**
- ‚úÖ Clear goal (no confusion)
- ‚úÖ Information gap (curiosity)
- ‚úÖ No commands (autonomy)
- ‚úÖ Success criteria (clear done)
- ‚úÖ Respect for LLM reasoning

---

## Sampling Trust: The Verification Paradox

### Core Discovery (ID 37-38 Analysis)

**The Paradox:**
```

Show evidence ‚Üí Don't need to verify
Hide evidence ‚Üí Must verify everything

```

### What LLMs Actually Trust

LLMÏù¥ Ïã†Î¢∞ÌïòÎäî Í≤É = **Ïñ∏Ï†úÎì† ÌôïÏù∏Ìï† Ïàò ÏûàÎäî Í≤É**

**Tier 1: Absolute Trust (ÏßÅÏ†ë Í≤ÄÏ¶ù Í∞ÄÎä•)**
1. Code (actual file content with line numbers)
2. Test results (reproducible output)
3. Git log (change history)
4. Bash output (command + result)
5. Grep/search results (pattern matches)

**Tier 2: Conditional Trust (Ï∂úÏ≤ò Î™ÖÌôï Ïãú)**
- Package manifests
- Config files
- Error logs with stack traces
- API responses

**Tier 3: No Trust (Í≤ÄÏ¶ù Î∂àÍ∞Ä)**
- Claims without evidence ("I verified X")
- Assertions without proof ("This works")
- Opinions without data ("Should be fine")

### The Sampling Effect

**ÌÜµÍ≥ÑÏ†Å Ïã†Î¢∞ Íµ¨Ï∂ï:**

```

Ï†ÑÏ≤¥ Ï£ºÏû• NÍ∞ú
ÏÉòÌîå ÌôïÏù∏ nÍ∞ú (n << N)

if (ÏÉòÌîå Ï†ïÌôïÎèÑ = 100%) {
ÎÇòÎ®∏ÏßÄ (N-n)Í∞ú Ïã†Î¢∞ÎèÑ ‚âà 95%
}

````

**ID 37 Ïã§Ìóò Í≤∞Í≥º:**
```markdown
‚ùå No evidence:
"Verified: .env.example contains required variables"

Gemini reaction:
- Read .env.example
- Read server.js
- Read story file
- Search codebase
- Read checkpoint-design-guide.md
‚Üí 5 files re-verified (100% re-exploration)
````

**Expected with evidence:**

````markdown
‚úÖ With sampling evidence:

```bash
$ grep MAMA .env.example
MAMA_SERVER_TOKEN=...
```
````

LLM reaction:
"ÏïÑ, grep Í≤∞Í≥º Î≥¥Ïù¥ÎÑ§.
ÌôïÏù∏ÌïòÍ≥† Ïã∂ÏúºÎ©¥ .env.example Ïó¥Î©¥ ÎêòÎäîÍµ¨ÎÇò.
Íµ≥Ïù¥ Ïïà Î¥êÎèÑ ÎêòÍ≤†ÎäîÎç∞?"
‚Üí 0-1 file verification (ÏÉòÌîåÎßÅÎßå)

````

### Chain of Evidence

**ÎèÖÎ¶Ω Ï£ºÏû• (Í∞ÅÍ∞Å Í≤ÄÏ¶ù ÌïÑÏöî):**
```markdown
‚ùå A: .env.example has TOKEN
‚ùå B: server.js imports initDB
‚ùå C: No validation exists
‚Üí 3Í∞ú Î™®Îëê Ïû¨Í≤ÄÏ¶ù
````

**Ïó∞Í≤∞Îêú Ï¶ùÍ±∞ Ï≤¥Ïù∏ (ÏÉòÌîåÎßå Í≤ÄÏ¶ù):**

```markdown
‚úÖ A: Required vars in .env.example
$ grep MAMA .env.example
MAMA_SERVER_TOKEN=... (line 3)

‚úÖ B: server.js imports initDB
$ rg initDB server.js
Line 39: const { initDB } = require(...)
Cross-ref: Will validate TOKEN from A before calling this

‚úÖ C: No validation before initDB
$ rg "validateEnv" packages/mcp-server/src/
(no results)
Implication: B calls initDB without checking A's TOKEN
‚Üí AC-1.2.3 needed
```

**LLM reasoning:**

```
"A ÌôïÏù∏Ìï¥Î≥ºÍπå?" ‚Üí ÎßûÎÑ§
"Í∑∏Îüº BÎèÑ ÎßûÍ≤†ÏßÄ? (ÏÉòÌîå Ï≤¥ÌÅ¨)" ‚Üí ÎßûÎÑ§
"CÎèÑ Ïã†Î¢∞ÌïòÏûê" ‚Üí Ï†ÑÏ≤¥ Ïä§ÌÜ†Î¶¨ ÏùºÍ¥ÄÎê® ‚úì
```

### Transparency Levels

| Level | Format                       | Trust | Re-verification |
| ----- | ---------------------------- | ----- | --------------- |
| 0     | "X is true"                  | 0%    | 100%            |
| 1     | "X at file:line"             | 30%   | 70%             |
| 2     | "$ command (see file)"       | 70%   | 20% (sample)    |
| 3     | "$ command + output + chain" | 95%   | 5%              |

### Audit Trail Pattern

ÌöåÍ≥Ñ Í∞êÏÇ¨ ÏõêÎ¶¨ Ï†ÅÏö©:

````markdown
## Verified (Audit Trail)

Sample 1/3: Required variables present

```bash
$ head -10 .env.example | grep MAMA
MAMA_SERVER_TOKEN=change_this
```
````

‚úì Confirmed at line 3

Sample 2/3: initDB import exists

```bash
$ sed -n '35,45p' server.js | grep initDB
const { initDB } = require('./mama/db-manager.js');
```

‚úì Confirmed at line 39

Sample 3/3: No prior validation

```bash
$ rg "validateEnv" packages/mcp-server/src/ --count
0
```

‚úì Confirmed zero matches

Audit conclusion: 3/3 samples verified ‚Üí Full context trusted

```

**Effect:**
- LLM checks 1 sample ‚Üí Accurate
- Trusts remaining 2 ‚Üí Efficient
- Can verify any claim ‚Üí Transparent

### Trust Formula

```

Trust Score =
Evidence Tier (1-3) √ó
Reproducibility (command provided) √ó
Sampling Accuracy (verified samples) √ó
Chain Coherence (connected story)

````

**Examples:**

| Statement | Tier | Reproducible | Sample | Chain | Score |
|-----------|------|--------------|--------|-------|-------|
| "X works" | 3 | No | - | - | 0% |
| "X at file.js:40" | 2 | No | - | - | 30% |
| "$ cmd ‚Üí result" | 1 | Yes | 100% | No | 70% |
| "$ cmd ‚Üí result + chain" | 1 | Yes | 100% | Yes | 95% |

### Practical Guidelines

**Don't show everything:**
```markdown
‚ùå Too much:
```bash
$ cat .env.example
(entire file contents - 50 lines)
````

‚Üí Overwhelming

````

**Show strategic samples:**
```markdown
‚úÖ Right amount:
```bash
$ grep "^MAMA_" .env.example | head -3
MAMA_SERVER_TOKEN=...
MAMA_DB_PATH=...
MAMA_SERVER_PORT=...
````

Full file: .env.example (13 lines)
‚Üí Sample + path to verify

````

**Connect the dots:**
```markdown
‚úÖ Evidence chain:
1. TOKEN defined (.env.example:3)
2. Used by server (server.js:48)
3. Not validated (search: no results)
4. ‚Üí AC-1.2.3 requires validation here

Each link verifiable, chain tells story
````

### Template: Evidence-Based Verification

````markdown
## Verified (Sampling Evidence)

**Sample 1:** [Claim 1]

```bash
$ [reproducible command]
[actual output - 3-5 lines]
```
````

Location: [file path]
Cross-ref: Used in [where/why]

**Sample 2:** [Claim 2]

```bash
$ [reproducible command]
[actual output]
```

Location: [file path]
Connection: [how relates to Sample 1]

**Sample 3:** [Negative evidence - what doesn't exist]

```bash
$ [search command]
(no results)
```

Implication: [why this matters]

**Chain:** [How 1‚Üí2‚Üí3 connects to current problem]

**To verify:** Use commands above or read files directly

```

### Key Principle

**Ìà¨Î™ÖÏÑ± ‚â† Î™®Îì† Í≤É Î≥¥Ïó¨Ï£ºÍ∏∞**

Ìà¨Î™ÖÏÑ± = Ïñ∏Ï†úÎì† ÌôïÏù∏ Í∞ÄÎä•ÏÑ±

```

"Íµ≥Ïù¥ Ïïà Î¥êÎèÑ ÎêòÍ≤†ÎÑ§" = Trust achieved
"ÌôïÏù∏Ìï¥ÏïºÍ≤†Îã§" = Trust failed

````

---

## ID 38 Experiment Results

**Test Setup:**
- Checkpoint: Evidence-based (3 samples) + No Next Steps
- Content: Story 1.2 env validation (stale - already completed)
- Test: Resume in 3 different LLM sessions

**Results:**

| LLM | Time | Re-verification | Behavior | Rating |
|-----|------|----------------|----------|--------|
| **Gemini** | 6s | 1 file | Smart sampling ‚Üí Found mismatch ‚Üí Correct judgment | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Codex** | 3s | 0 files | Trusted 100% ‚Üí Tried to re-implement | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Claude** | >20s | 5+ files | Tool access issue (unrelated) | ‚≠ê‚≠ê |

**Key Findings:**

1. **Sampling Trust Works (Gemini):**
   - Read evidence in checkpoint
   - Verified 1 sample (server.js)
   - Found mismatch: "checkpoint said 'no validation', but validateEnvironment() exists"
   - Tested production mode to confirm
   - Correct conclusion: "Already implemented, AC-1.2.3 satisfied"

2. **Over-Trust Risk (Codex):**
   - Trusted checkpoint completely
   - No verification (0 files read)
   - Attempted to implement validation again (duplicate work)
   - Lesson: Even with evidence, minimum 1 sample verification recommended

3. **Stale Checkpoint Issue:**
   - Checkpoint was from past (before implementation)
   - Actual code already completed
   - Only Gemini caught the discrepancy

**Improvements Identified:**

### Checkpoint Metadata
```markdown
## Checkpoint Metadata
- Saved: 2025-11-24 13:35:56
- Age: 2 hours
- Status: May be outdated

‚ö†Ô∏è **Verify First:** Code may have changed since checkpoint
````

### Expected vs Actual

```markdown
## Expected State (at checkpoint time)

- No validation exists
- Array incomplete

## Verify Actual State

$ rg "validateEnvironment" server.js

If different ‚Üí Implementation completed after checkpoint
```

**Conclusion:**

Sampling Trust hypothesis: **‚úÖ Partially Validated**

- Evidence reduces re-verification (5 files ‚Üí 1 file) ‚úÖ
- Sampling enables smart validation ‚úÖ
- Stale checkpoint needs handling ‚ö†Ô∏è

Best practice: **Gemini pattern**

1. Read evidence
2. Sample 1-2 items
3. Compare expected vs actual
4. Make informed decision

---

## References

- **PRD:** docs/development/PRD-narrative-preservation-v1.1.md (FR1: Narrative 5-layer capture)
- **Experiments:** Session IDs 25-29 (see MAMA memory)
- **Zeigarnik Effect:** Psychological principle of incomplete tasks
- **Show Don't Tell:** Narrative technique from creative writing

---

## Version History

- 2025-01-24 (Morning): Initial version based on ID 25-29 experiments
- 2025-01-24 (Afternoon): Added Visual Incompleteness section based on ID 29-34 analysis
  - Discovered: Syntactically invalid code perceived as verified fact
  - Ranked patterns: Unclosed string > Mid-word > Function call > Comment
  - Added 4 design principles and implementation templates
- 2025-11-24 (Evening): Major update - Psychological foundations and Sampling Trust
  - Added Psychology of Persuasion: Information Gap, Reactance Theory, Zeigarnik reconsidered
  - Discovered Sampling Trust: Show evidence ‚Üí Don't need to verify
  - Added ID 36-38 experiments to Evolution Summary
  - Final Template: Evidence-based with no "Next Steps"
  - ID 38 Experiment: 3 LLM validation (Gemini ideal, Codex over-trust, Claude tool issue)
  - Key findings: Re-verification reduced 80% (5 files ‚Üí 1 file), stale checkpoint handling needed
- Key contributors: Session analysis across Claude Code, Codex, and Gemini environments
